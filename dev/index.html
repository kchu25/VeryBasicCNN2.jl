<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · VeryBasicCNN2.jl</title><meta name="title" content="Home · VeryBasicCNN2.jl"/><meta property="og:title" content="Home · VeryBasicCNN2.jl"/><meta property="twitter:title" content="Home · VeryBasicCNN2.jl"/><meta name="description" content="Documentation for VeryBasicCNN2.jl."/><meta property="og:description" content="Documentation for VeryBasicCNN2.jl."/><meta property="twitter:description" content="Documentation for VeryBasicCNN2.jl."/><meta property="og:url" content="https://kchu25.github.io/VeryBasicCNN2.jl/"/><meta property="twitter:url" content="https://kchu25.github.io/VeryBasicCNN2.jl/"/><link rel="canonical" href="https://kchu25.github.io/VeryBasicCNN2.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>VeryBasicCNN2.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/kchu25/VeryBasicCNN2.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="VeryBasicCNN2"><a class="docs-heading-anchor" href="#VeryBasicCNN2">VeryBasicCNN2</a><a id="VeryBasicCNN2-1"></a><a class="docs-heading-anchor-permalink" href="#VeryBasicCNN2" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/kchu25/VeryBasicCNN2.jl">VeryBasicCNN2</a>.</p><ul><li><a href="#VeryBasicCNN2.CodeProcessor-Tuple{Any}"><code>VeryBasicCNN2.CodeProcessor</code></a></li><li><a href="#VeryBasicCNN2.CodeProcessor"><code>VeryBasicCNN2.CodeProcessor</code></a></li><li><a href="#VeryBasicCNN2.CodeProcessorType"><code>VeryBasicCNN2.CodeProcessorType</code></a></li><li><a href="#VeryBasicCNN2.HyperParamRanges"><code>VeryBasicCNN2.HyperParamRanges</code></a></li><li><a href="#VeryBasicCNN2.HyperParameters"><code>VeryBasicCNN2.HyperParameters</code></a></li><li><a href="#VeryBasicCNN2.LearnedCodeImgFilters-Tuple{Any, HyperParameters}"><code>VeryBasicCNN2.LearnedCodeImgFilters</code></a></li><li><a href="#VeryBasicCNN2.LearnedCodeImgFilters"><code>VeryBasicCNN2.LearnedCodeImgFilters</code></a></li><li><a href="#VeryBasicCNN2.LearnedPWMs"><code>VeryBasicCNN2.LearnedPWMs</code></a></li><li><a href="#VeryBasicCNN2.LearnedPWMs-Tuple{Any}"><code>VeryBasicCNN2.LearnedPWMs</code></a></li><li><a href="#VeryBasicCNN2.MBConvBlock"><code>VeryBasicCNN2.MBConvBlock</code></a></li><li><a href="#VeryBasicCNN2.SeqCNN-Tuple{Any}"><code>VeryBasicCNN2.SeqCNN</code></a></li><li><a href="#VeryBasicCNN2.SeqCNN"><code>VeryBasicCNN2.SeqCNN</code></a></li><li><a href="#Base.getproperty-Tuple{SeqCNN, Symbol}"><code>Base.getproperty</code></a></li><li><a href="#VeryBasicCNN2.amino_acid_ranges-Tuple{}"><code>VeryBasicCNN2.amino_acid_ranges</code></a></li><li><a href="#VeryBasicCNN2.batched_mul-Tuple{Any, Any}"><code>VeryBasicCNN2.batched_mul</code></a></li><li><a href="#VeryBasicCNN2.clamp_positive-Tuple{Any}"><code>VeryBasicCNN2.clamp_positive</code></a></li><li><a href="#VeryBasicCNN2.compute_code_at_layer-Tuple{SeqCNN, Any, Int64}"><code>VeryBasicCNN2.compute_code_at_layer</code></a></li><li><a href="#VeryBasicCNN2.compute_training_loss-Tuple{SeqCNN, Any, Any}"><code>VeryBasicCNN2.compute_training_loss</code></a></li><li><a href="#VeryBasicCNN2.conv-Tuple{Any, Any}"><code>VeryBasicCNN2.conv</code></a></li><li><a href="#VeryBasicCNN2.conv_output_length-Tuple{Any, Any}"><code>VeryBasicCNN2.conv_output_length</code></a></li><li><a href="#VeryBasicCNN2.conv_pool_output_length-NTuple{4, Any}"><code>VeryBasicCNN2.conv_pool_output_length</code></a></li><li><a href="#VeryBasicCNN2.create_code_processor-Tuple{HyperParameters}"><code>VeryBasicCNN2.create_code_processor</code></a></li><li><a href="#VeryBasicCNN2.create_model-Tuple{Any, Any, Int64}"><code>VeryBasicCNN2.create_model</code></a></li><li><a href="#VeryBasicCNN2.create_pwm-Tuple{Any}"><code>VeryBasicCNN2.create_pwm</code></a></li><li><a href="#VeryBasicCNN2.efficientnet_mbconv_config"><code>VeryBasicCNN2.efficientnet_mbconv_config</code></a></li><li><a href="#VeryBasicCNN2.extract_features-Tuple{SeqCNN, Any}"><code>VeryBasicCNN2.extract_features</code></a></li><li><a href="#VeryBasicCNN2.final_conv_embedding_length-Tuple{HyperParameters, Int64}"><code>VeryBasicCNN2.final_conv_embedding_length</code></a></li><li><a href="#VeryBasicCNN2.format_predictions-Tuple{Any}"><code>VeryBasicCNN2.format_predictions</code></a></li><li><a href="#VeryBasicCNN2.forward_conv_recursive"><code>VeryBasicCNN2.forward_conv_recursive</code></a></li><li><a href="#VeryBasicCNN2.generate_random_hyperparameters-Tuple{}"><code>VeryBasicCNN2.generate_random_hyperparameters</code></a></li><li><a href="#VeryBasicCNN2.huber_loss-Tuple{Any, Any}"><code>VeryBasicCNN2.huber_loss</code></a></li><li><a href="#VeryBasicCNN2.layernorm-Tuple{Any, Any, Any}"><code>VeryBasicCNN2.layernorm</code></a></li><li><a href="#VeryBasicCNN2.masked_mse-Tuple{Any, Any, Any}"><code>VeryBasicCNN2.masked_mse</code></a></li><li><a href="#VeryBasicCNN2.maxpool-Tuple{Any}"><code>VeryBasicCNN2.maxpool</code></a></li><li><a href="#VeryBasicCNN2.model2cpu-Tuple{SeqCNN}"><code>VeryBasicCNN2.model2cpu</code></a></li><li><a href="#VeryBasicCNN2.model2gpu-Tuple{SeqCNN}"><code>VeryBasicCNN2.model2gpu</code></a></li><li><a href="#VeryBasicCNN2.normalize_filters_l2-Tuple{Any}"><code>VeryBasicCNN2.normalize_filters_l2</code></a></li><li><a href="#VeryBasicCNN2.normalize_squared-Tuple{Any}"><code>VeryBasicCNN2.normalize_squared</code></a></li><li><a href="#VeryBasicCNN2.nucleotide_ranges-Tuple{}"><code>VeryBasicCNN2.nucleotide_ranges</code></a></li><li><a href="#VeryBasicCNN2.pool_code-Tuple{Any, Any, Any}"><code>VeryBasicCNN2.pool_code</code></a></li><li><a href="#VeryBasicCNN2.pool_output_length-Tuple{Any, Any, Any}"><code>VeryBasicCNN2.pool_output_length</code></a></li><li><a href="#VeryBasicCNN2.predict_from_code-Tuple{SeqCNN, Any}"><code>VeryBasicCNN2.predict_from_code</code></a></li><li><a href="#VeryBasicCNN2.predict_from_sequences-Tuple{SeqCNN, Any}"><code>VeryBasicCNN2.predict_from_sequences</code></a></li><li><a href="#VeryBasicCNN2.prepare_conv_params-Tuple{LearnedCodeImgFilters, HyperParameters}"><code>VeryBasicCNN2.prepare_conv_params</code></a></li><li><a href="#VeryBasicCNN2.prepare_pwm_params-Tuple{LearnedPWMs}"><code>VeryBasicCNN2.prepare_pwm_params</code></a></li><li><a href="#VeryBasicCNN2.process_code_with_gradient-Tuple{CodeProcessor, Any, Any}"><code>VeryBasicCNN2.process_code_with_gradient</code></a></li><li><a href="#VeryBasicCNN2.receptive_field-Tuple{HyperParameters}"><code>VeryBasicCNN2.receptive_field</code></a></li><li><a href="#VeryBasicCNN2.select_output_weights-Tuple{SeqCNN}"><code>VeryBasicCNN2.select_output_weights</code></a></li><li><a href="#VeryBasicCNN2.square_clamp-Tuple{Any}"><code>VeryBasicCNN2.square_clamp</code></a></li><li><a href="#VeryBasicCNN2.with_batch_size-Tuple{HyperParameters, Int64}"><code>VeryBasicCNN2.with_batch_size</code></a></li><li><a href="#VeryBasicCNN2.with_efficientnet_mbconv"><code>VeryBasicCNN2.with_efficientnet_mbconv</code></a></li><li><a href="#VeryBasicCNN2.with_layernorm"><code>VeryBasicCNN2.with_layernorm</code></a></li><li><a href="#VeryBasicCNN2.with_mbconv-Tuple{HyperParameters}"><code>VeryBasicCNN2.with_mbconv</code></a></li></ul><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.CodeProcessor"><a class="docstring-binding" href="#VeryBasicCNN2.CodeProcessor"><code>VeryBasicCNN2.CodeProcessor</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">CodeProcessor</code></pre><p>Network for processing concatenated code and gradient features.</p><p><strong>Fields</strong></p><ul><li><code>expand_filters</code>: Channel expansion (optional, for mbconv)</li><li><code>dw_filters</code>: Depthwise convolution filters</li><li><code>se_w1, se_w2</code>: Squeeze-excitation weights (optional, for mbconv)</li><li><code>project_filters</code>: Channel projection back to output size</li><li><code>use_residual</code>: Whether to use skip connection</li><li><code>arch_type</code>: Architecture type (:plain, :resnet, :mbconv, :deep_plain)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/code_processor.jl#L19-L31">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.CodeProcessor-Tuple{Any}"><a class="docstring-binding" href="#VeryBasicCNN2.CodeProcessor-Tuple{Any}"><code>VeryBasicCNN2.CodeProcessor</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">(cp::CodeProcessor)(x; training::Bool=true, step::Union{Nothing, Int}=nothing)</code></pre><p>Forward pass through code processor.</p><p><strong>Process</strong></p><ol><li>Optional expansion (mbconv only)</li><li>Depthwise convolution + activation</li><li>Optional SE attention (mbconv only)</li><li>Projection back to output channels</li><li>Optional hard mask (if enabled)</li><li>Optional residual connection (resnet, mbconv)</li></ol><p><strong>Arguments</strong></p><ul><li><code>x</code>: Input tensor (spatial, channels, 1, batch)</li><li><code>training</code>: Whether in training mode (affects Gumbel sampling in hard mask)</li><li><code>step</code>: Training step number (for temperature annealing). If nothing, uses fixed cp.mask_temp</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/code_processor.jl#L198-L215">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.CodeProcessorType"><a class="docstring-binding" href="#VeryBasicCNN2.CodeProcessorType"><code>VeryBasicCNN2.CodeProcessorType</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">CodeProcessorType</code></pre><p>Type of architecture for code processing.</p><ul><li><code>:plain</code>: Simple depthwise convolution</li><li><code>:resnet</code>: Depthwise conv with residual connection</li><li><code>:mbconv</code>: MBConv-style with expansion and SE attention</li><li><code>:deep_plain</code>: Stacked plain layers (2 layers for more capacity)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/code_processor.jl#L8-L16">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.HyperParamRanges"><a class="docstring-binding" href="#VeryBasicCNN2.HyperParamRanges"><code>VeryBasicCNN2.HyperParamRanges</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">HyperParamRanges</code></pre><p>Specification of valid ranges for random hyperparameter generation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/param_ranges.jl#L5-L9">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.HyperParameters"><a class="docstring-binding" href="#VeryBasicCNN2.HyperParameters"><code>VeryBasicCNN2.HyperParameters</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">HyperParameters</code></pre><p>CNN hyperparameters for biological sequence analysis.</p><p><strong>Architecture Fields</strong></p><ul><li><code>pfm_len::Int</code>: Length of Position Weight Matrix filters (motif length)</li><li><code>num_pfms::Int</code>: Number of PWM filters in base layer</li><li><code>num_img_filters::Vector{Int}</code>: Number of filters per convolutional layer</li><li><code>img_fil_widths::Vector{Int}</code>: Input channels for each conv layer</li><li><code>img_fil_heights::Vector{Int}</code>: Filter heights for each conv layer</li></ul><p><strong>Pooling Fields</strong></p><ul><li><code>pool_base::Int</code>: Pooling size for base layer</li><li><code>stride_base::Int</code>: Stride for base layer pooling</li><li><code>poolsize::Vector{Int}</code>: Pooling sizes for each conv layer</li><li><code>stride::Vector{Int}</code>: Strides for each conv layer</li><li><code>pool_lvl_top::Int</code>: Highest layer index that uses pooling</li></ul><p><strong>Training Fields</strong></p><ul><li><code>softmax_strength_img_fil::Float32</code>: Softmax strength for filter normalization</li><li><code>batch_size::Int</code>: Training batch size</li><li><code>inference_code_layer::Int</code>: Layer to extract code from (0 = PWM layer)</li></ul><p><strong>Normalization Fields</strong></p><ul><li><code>use_layernorm::Bool</code>: Apply LayerNorm after pooling for layers &gt; inference<em>code</em>layer (default: false)</li></ul><p><strong>MBConv Fields</strong></p><ul><li><code>num_mbconv::Int</code>: Number of MBConv blocks to add (0 = none, default)</li><li><code>mbconv_expansion::Int</code>: MBConv expansion ratio (default: 4)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/struct_definition.jl#L5-L35">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.LearnedCodeImgFilters"><a class="docstring-binding" href="#VeryBasicCNN2.LearnedCodeImgFilters"><code>VeryBasicCNN2.LearnedCodeImgFilters</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">LearnedCodeImgFilters</code></pre><p>Learnable convolutional filters for intermediate CNN layers.</p><p><strong>Fields</strong></p><ul><li><code>filters</code>: 4D array (height, width, 1, num_filters)</li><li><code>ln_gamma</code>: LayerNorm scale parameter (optional, per channel)</li><li><code>ln_beta</code>: LayerNorm shift parameter (optional, per channel)</li></ul><p><strong>Forward Pass</strong></p><p>Applies normalized convolution followed by ReLU activation, optionally with LayerNorm.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/layers/conv.jl#L32-L45">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.LearnedCodeImgFilters-Tuple{Any, HyperParameters}"><a class="docstring-binding" href="#VeryBasicCNN2.LearnedCodeImgFilters-Tuple{Any, HyperParameters}"><code>VeryBasicCNN2.LearnedCodeImgFilters</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">(conv_filters::LearnedCodeImgFilters)(code_input, hp::HyperParameters; use_sparsity=false)</code></pre><p>Forward pass through convolutional layer.</p><p><strong>Process</strong></p><ol><li>L2-normalize filters (optionally with sparsity)</li><li>Convolve with input code</li><li>Apply ReLU activation</li></ol><p><strong>Returns</strong></p><ul><li>Activated code (4D: height, width, filters, batch)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/layers/conv.jl#L105-L117">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.LearnedPWMs"><a class="docstring-binding" href="#VeryBasicCNN2.LearnedPWMs"><code>VeryBasicCNN2.LearnedPWMs</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">LearnedPWMs</code></pre><p>Learnable Position Weight Matrices for the first CNN layer.</p><p><strong>Fields</strong></p><ul><li><code>filters</code>: 4D array (alphabet<em>size, motif</em>len, 1, num_filters)</li><li><code>activation_scaler</code>: Scalar activation parameter</li></ul><p><strong>Forward Pass</strong></p><p>Applies PWM convolution followed by ReLU activation scaled by learned parameter.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/layers/pwm.jl#L5-L16">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.LearnedPWMs-Tuple{Any}"><a class="docstring-binding" href="#VeryBasicCNN2.LearnedPWMs-Tuple{Any}"><code>VeryBasicCNN2.LearnedPWMs</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">(pwms::LearnedPWMs)(sequences; reverse_comp=false)</code></pre><p>Forward pass through PWM layer.</p><p><strong>Process</strong></p><ol><li>Create PWM from learned frequencies</li><li>Convolve with input sequences  </li><li>Apply ReLU with learned scaling</li></ol><p><strong>Returns</strong></p><ul><li>Code activations (3D: length, filters, batch)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/layers/pwm.jl#L62-L74">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.MBConvBlock"><a class="docstring-binding" href="#VeryBasicCNN2.MBConvBlock"><code>VeryBasicCNN2.MBConvBlock</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">MBConvBlock</code></pre><p>Mobile Inverted Bottleneck Convolution (MBConv) block with SE attention.</p><p><strong>Fields</strong></p><ul><li><code>expand_filters</code>: Expansion filters (1, in_channels, 1, expanded)</li><li><code>dw_filters</code>: Depthwise filters (kernel_size, 1, 1, expanded)</li><li><code>se_w1</code>: SE reduction weights (se_channels, expanded, 1)</li><li><code>se_w2</code>: SE expansion weights (expanded, se_channels, 1)</li><li><code>project_filters</code>: Projection filters (1, expanded, 1, out_channels)</li><li><code>use_skip</code>: Whether to use skip connection</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/layers/mbconv.jl#L5-L17">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.SeqCNN"><a class="docstring-binding" href="#VeryBasicCNN2.SeqCNN"><code>VeryBasicCNN2.SeqCNN</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">SeqCNN</code></pre><p>Convolutional neural network for biological sequence analysis.</p><p><strong>Architecture</strong></p><ol><li><strong>Base Layer</strong>: Learnable PWMs for motif detection</li><li><strong>Conv Layers</strong>: Hierarchical feature extraction with pooling</li><li><strong>MBConv Blocks</strong> (optional): EfficientNet-style refinement</li><li><strong>Output Layer</strong>: Linear transformation to predictions</li></ol><p><strong>Fields</strong></p><ul><li><code>hp::HyperParameters</code>: Architecture configuration</li><li><code>pwms::LearnedPWMs</code>: Base layer PWM filters</li><li><code>conv_layers::Vector{LearnedCodeImgFilters}</code>: Convolutional layers</li><li><code>mbconv_blocks::Vector{MBConvBlock}</code>: Optional MBConv refinement blocks</li><li><code>output_weights::Array{Float32,3}</code>: Final linear layer (output<em>dim × embed</em>dim × 1)</li></ul><p><strong>Constructor</strong></p><pre><code class="language-julia hljs">SeqCNN(hp, input_dims, output_dim; init_scale=0.5, use_cuda=true, rng=Random.GLOBAL_RNG)</code></pre><p><strong>Arguments</strong></p><ul><li><code>hp</code>: HyperParameters specifying architecture</li><li><code>input_dims</code>: Tuple (alphabet<em>size, sequence</em>length)</li><li><code>output_dim</code>: Number of output targets</li><li><code>init_scale</code>: Weight initialization scale</li><li><code>use_cuda</code>: Whether to place on GPU</li><li><code>rng</code>: Random number generator</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">hp = generate_random_hyperparameters()
model = SeqCNN(hp, (4, 41), 244)  # DNA sequences, 244 outputs
predictions = model(sequences)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/model.jl#L5-L40">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.SeqCNN-Tuple{Any}"><a class="docstring-binding" href="#VeryBasicCNN2.SeqCNN-Tuple{Any}"><code>VeryBasicCNN2.SeqCNN</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">(model::SeqCNN)(sequences; use_sparsity=false, linear_sum=false, predict_position=nothing)</code></pre><p>Callable interface for SeqCNN forward pass.</p><p><strong>Arguments</strong></p><ul><li><code>sequences</code>: Input sequences</li><li><code>use_sparsity</code>: Apply sparsity-inducing normalization</li><li><code>linear_sum</code>: Return sum of linear outputs (for optimization)</li><li><code>predict_position</code>: Predict specific output position</li></ul><p><strong>Returns</strong></p><ul><li>Model predictions</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs"># Standard prediction
preds = model(sequences)

# Linear sum for gradient-based optimization
loss_term = model(sequences; linear_sum=true, predict_position=1)

# Sparse filters
preds_sparse = model(sequences; use_sparsity=true)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/forward.jl#L276-L301">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Base.getproperty-Tuple{SeqCNN, Symbol}"><a class="docstring-binding" href="#Base.getproperty-Tuple{SeqCNN, Symbol}"><code>Base.getproperty</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Custom property access for convenient model introspection and utilities.</p><p><strong>Virtual Properties</strong></p><ul><li><code>model.num_conv_layers</code>: Number of convolutional layers</li><li><code>model.receptive_field</code>: Receptive field at inference layer</li><li><code>model.code</code>: Function to extract code at inference layer</li><li><code>model.first_layer_code</code>: Function to extract base PWM code</li><li><code>model.linear_sum</code>: Function for linear output sum (optimization)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/model.jl#L132-L141">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.amino_acid_ranges-Tuple{}"><a class="docstring-binding" href="#VeryBasicCNN2.amino_acid_ranges-Tuple{}"><code>VeryBasicCNN2.amino_acid_ranges</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">amino_acid_ranges(; kwargs...)</code></pre><p>Hyperparameter ranges optimized for amino acid sequences (proteins). 20-letter alphabet, larger filters needed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/param_ranges.jl#L53-L58">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.batched_mul-Tuple{Any, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.batched_mul-Tuple{Any, Any}"><code>VeryBasicCNN2.batched_mul</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">batched_mul(A, B)</code></pre><p>Batched matrix multiplication wrapper for Flux.NNlib.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L211-L215">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.clamp_positive-Tuple{Any}"><a class="docstring-binding" href="#VeryBasicCNN2.clamp_positive-Tuple{Any}"><code>VeryBasicCNN2.clamp_positive</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">clamp_positive(x; upper=25)</code></pre><p>ReLU with upper bound: <code>min(upper, max(0, x))</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L192-L196">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.compute_code_at_layer-Tuple{SeqCNN, Any, Int64}"><a class="docstring-binding" href="#VeryBasicCNN2.compute_code_at_layer-Tuple{SeqCNN, Any, Int64}"><code>VeryBasicCNN2.compute_code_at_layer</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">compute_code_at_layer(model::SeqCNN, sequences, layer; use_sparsity=false)</code></pre><p>Compute code representation at specified layer depth.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: SeqCNN instance</li><li><code>sequences</code>: Input sequences (4D tensor)</li><li><code>layer</code>: Target layer (0 = base PWM, 1+ = conv layers)</li><li><code>use_sparsity</code>: Apply sparsity-inducing normalization</li></ul><p><strong>Returns</strong></p><ul><li>Code tensor at specified layer</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">code_pwm = compute_code_at_layer(model, seqs, 0)      # Base PWM code
code_l1 = compute_code_at_layer(model, seqs, 1)       # After 1st conv
code_final = compute_code_at_layer(model, seqs, 3)    # After 3rd conv</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/forward.jl#L5-L25">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.compute_training_loss-Tuple{SeqCNN, Any, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.compute_training_loss-Tuple{SeqCNN, Any, Any}"><code>VeryBasicCNN2.compute_training_loss</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">compute_training_loss(model::SeqCNN, sequences, targets; use_sparsity=false, verbose=true)</code></pre><p>Compute training loss for the CNN model.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: SeqCNN instance</li><li><code>sequences</code>: Input biological sequences</li><li><code>targets</code>: Ground truth target values</li><li><code>use_sparsity</code>: Apply sparsity-inducing normalization</li><li><code>verbose</code>: Print loss value</li></ul><p><strong>Returns</strong></p><ul><li>Scalar loss value for optimization</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/loss.jl#L73-L87">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.conv-Tuple{Any, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.conv-Tuple{Any, Any}"><code>VeryBasicCNN2.conv</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">conv(x, w; pad=0, flipped=true)</code></pre><p>Convolution operation wrapper.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L218-L222">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.conv_output_length-Tuple{Any, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.conv_output_length-Tuple{Any, Any}"><code>VeryBasicCNN2.conv_output_length</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">conv_output_length(input_len, filter_len)</code></pre><p>Output length after 1D convolution: <code>input_len - filter_len + 1</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L5-L9">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.conv_pool_output_length-NTuple{4, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.conv_pool_output_length-NTuple{4, Any}"><code>VeryBasicCNN2.conv_pool_output_length</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">conv_pool_output_length(input_len, filter_len, pool_size, stride)</code></pre><p>Output length after convolution followed by pooling.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L20-L24">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.create_code_processor-Tuple{HyperParameters}"><a class="docstring-binding" href="#VeryBasicCNN2.create_code_processor-Tuple{HyperParameters}"><code>VeryBasicCNN2.create_code_processor</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">create_code_processor(hp::HyperParameters; 
                      arch_type=mbconv,
                      kernel_size=3,
                      expansion_ratio=2,
                      use_cuda=true,
                      rng=Random.GLOBAL_RNG)</code></pre><p>Create a CodeProcessor network based on hyperparameters.</p><p><strong>Arguments</strong></p><ul><li><code>hp</code>: HyperParameters (determines input/output dimensions)</li><li><code>arch_type</code>: Architecture type (:plain, :resnet, or :mbconv)</li><li><code>kernel_size</code>: Depthwise convolution kernel size</li><li><code>expansion_ratio</code>: Channel expansion ratio (mbconv only)</li><li><code>use_cuda</code>: Whether to use GPU</li><li><code>rng</code>: Random number generator</li></ul><p><strong>Returns</strong></p><ul><li>CodeProcessor instance</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">hp = generate_random_hyperparameters()

# Plain depthwise conv
proc_plain = create_code_processor(hp; arch_type=plain)

# ResNet-style with residual
proc_resnet = create_code_processor(hp; arch_type=resnet)

# MBConv-style with SE attention
proc_mbconv = create_code_processor(hp; arch_type=mbconv, expansion_ratio=4)

# Forward pass: concatenate code and gradient along channel dimension
# code_and_grad = cat(code, gradient; dims=2)
# output = proc(code_and_grad)  # Same size as code</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/code_processor.jl#L416-L454">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.create_model-Tuple{Any, Any, Int64}"><a class="docstring-binding" href="#VeryBasicCNN2.create_model-Tuple{Any, Any, Int64}"><code>VeryBasicCNN2.create_model</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">create_model(input_dims, output_dim, batch_size; rng=Random.GLOBAL_RNG, use_cuda=true, ranges=DEFAULT_RANGES)</code></pre><p>Create a SeqCNN with randomly generated hyperparameters.</p><p><strong>Arguments</strong></p><ul><li><code>input_dims</code>: Tuple (alphabet<em>size, sequence</em>length)</li><li><code>output_dim</code>: Number of output targets</li><li><code>batch_size</code>: Training batch size</li><li><code>rng</code>: Random number generator</li><li><code>use_cuda</code>: Whether to use GPU</li><li><code>ranges</code>: HyperParamRanges for architecture sampling</li></ul><p><strong>Returns</strong></p><ul><li>SeqCNN instance, or <code>nothing</code> if architecture is invalid</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs"># DNA sequences
model = create_model((4, 41), 244, 128; ranges=nucleotide_ranges())

# Protein sequences
model = create_model((20, 100), 1, 64; ranges=amino_acid_ranges())</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/model.jl#L180-L204">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.create_pwm-Tuple{Any}"><a class="docstring-binding" href="#VeryBasicCNN2.create_pwm-Tuple{Any}"><code>VeryBasicCNN2.create_pwm</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">create_pwm(frequencies; reverse_comp=false)</code></pre><p>Create Position Weight Matrix from frequency matrix. Converts to log2 odds ratios relative to background.</p><p>PWM[i,j] = log2(freq[i,j] / background[i])</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L145-L152">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.efficientnet_mbconv_config"><a class="docstring-binding" href="#VeryBasicCNN2.efficientnet_mbconv_config"><code>VeryBasicCNN2.efficientnet_mbconv_config</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">efficientnet_mbconv_config(phi::Int=0)</code></pre><p>Get EfficientNet-style MBConv configuration based on compound scaling coefficient φ.</p><p><strong>EfficientNet Scaling</strong></p><ul><li>φ=0 (B0): num_blocks=2, expansion=4  (baseline)</li><li>φ=1 (B1): num_blocks=3, expansion=4  (1.2× depth)</li><li>φ=2 (B2): num_blocks=3, expansion=6  (1.4× depth, wider)</li><li>φ=3 (B3): num_blocks=4, expansion=6  (1.8× depth)</li><li>φ=4 (B4): num_blocks=5, expansion=6  (2.2× depth)</li></ul><p><strong>Returns</strong></p><ul><li><code>(num_blocks, expansion)</code>: Configuration tuple</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">hp = generate_random_hyperparameters()
num_blocks, expansion = efficientnet_mbconv_config(2)  # B2 config
hp_b2 = with_mbconv(hp; num_blocks=num_blocks, expansion=expansion)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/utilities.jl#L133-L154">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.extract_features-Tuple{SeqCNN, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.extract_features-Tuple{SeqCNN, Any}"><code>VeryBasicCNN2.extract_features</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">extract_features(model::SeqCNN, sequences; use_sparsity=false)</code></pre><p>Extract CNN features from sequences (full forward pass through all conv layers).</p><p><strong>Process</strong></p><ol><li>Base PWM layer → pool</li><li>All conv layers → pool</li><li>Optional MBConv refinement blocks</li><li>Flatten to embedding vector</li></ol><p><strong>Returns</strong></p><ul><li>Feature embedding (embed<em>dim, 1, batch</em>size)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/forward.jl#L88-L101">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.final_conv_embedding_length-Tuple{HyperParameters, Int64}"><a class="docstring-binding" href="#VeryBasicCNN2.final_conv_embedding_length-Tuple{HyperParameters, Int64}"><code>VeryBasicCNN2.final_conv_embedding_length</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">final_conv_embedding_length(hp::HyperParameters, seq_len::Int)</code></pre><p>Calculate the spatial dimension after all conv/pool layers. This simulates the full forward pass dimensionality.</p><p><strong>Process</strong></p><ol><li>Base layer: conv with PWM → pool</li><li>Each layer ≤ pool<em>lvl</em>top: conv → pool</li><li>Remaining layers: conv only (no pool)</li></ol><p>Returns 0 if any dimension becomes invalid (≤ 0).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L28-L40">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.format_predictions-Tuple{Any}"><a class="docstring-binding" href="#VeryBasicCNN2.format_predictions-Tuple{Any}"><code>VeryBasicCNN2.format_predictions</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">format_predictions(linear_output)</code></pre><p>Format linear output to appropriate prediction shape.</p><p><strong>Returns</strong></p><ul><li>1D vector for single output</li><li>2D matrix for multi-output (output<em>dim, batch</em>size)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/forward.jl#L148-L156">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.forward_conv_recursive"><a class="docstring-binding" href="#VeryBasicCNN2.forward_conv_recursive"><code>VeryBasicCNN2.forward_conv_recursive</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">forward_conv_recursive(model, code, current_layer, target_layer; use_sparsity=false)</code></pre><p>Recursively process convolutional layers.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: SeqCNN instance</li><li><code>code</code>: Current code representation</li><li><code>current_layer</code>: Current layer index (1-indexed)</li><li><code>target_layer</code>: Stop at this layer (nothing = process all)</li><li><code>use_sparsity</code>: Apply sparsity-inducing normalization</li></ul><p><strong>Returns</strong></p><ul><li>Code after processing layers up to target_layer</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/forward.jl#L43-L57">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.generate_random_hyperparameters-Tuple{}"><a class="docstring-binding" href="#VeryBasicCNN2.generate_random_hyperparameters-Tuple{}"><code>VeryBasicCNN2.generate_random_hyperparameters</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">generate_random_hyperparameters(; batch_size=nothing, rng=Random.GLOBAL_RNG, ranges=DEFAULT_RANGES)</code></pre><p>Generate randomized hyperparameters for architecture search.</p><p><strong>Arguments</strong></p><ul><li><code>batch_size</code>: Fixed batch size (defaults to random selection from ranges)</li><li><code>rng</code>: Random number generator for reproducibility</li><li><code>ranges</code>: HyperParamRanges defining valid parameter ranges</li></ul><p><strong>Returns</strong></p><ul><li><code>HyperParameters</code> instance with randomized valid configuration</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/random_generation.jl#L5-L17">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.huber_loss-Tuple{Any, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.huber_loss-Tuple{Any, Any}"><code>VeryBasicCNN2.huber_loss</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">huber_loss(predictions, targets; delta=0.85, quadratic_weight=0.5)</code></pre><p>Compute Huber loss with automatic NaN handling.</p><p>The Huber loss combines quadratic loss for small errors and linear loss  for large errors, providing robustness to outliers.</p><p><strong>Formula</strong></p><ul><li>For |error| &lt; δ: L = α * error²</li><li>For |error| ≥ δ: L = δ * (|error| - α * δ)</li></ul><p><strong>Arguments</strong></p><ul><li><code>predictions</code>: Model predictions</li><li><code>targets</code>: Ground truth values</li><li><code>delta</code>: Threshold between quadratic and linear regions</li><li><code>quadratic_weight</code>: Weight factor α for quadratic term</li></ul><p><strong>Returns</strong></p><ul><li>Mean Huber loss over valid (non-NaN) entries</li></ul><p><strong>Notes</strong></p><ul><li>NaN values in targets are automatically excluded</li><li>Differentiable for gradient-based optimization</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/loss.jl#L5-L29">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.layernorm-Tuple{Any, Any, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.layernorm-Tuple{Any, Any, Any}"><code>VeryBasicCNN2.layernorm</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">layernorm(x, gamma, beta; eps=DEFAULT_FLOAT_TYPE(1e-5))</code></pre><p>Apply Layer Normalization.</p><p><strong>Arguments</strong></p><ul><li><code>x</code>: Input tensor (height, width, channels, batch)</li><li><code>gamma</code>: Scale parameters (per channel)</li><li><code>beta</code>: Shift parameters (per channel)</li><li><code>eps</code>: Numerical stability constant</li></ul><p><strong>Returns</strong></p><ul><li>Normalized and affine-transformed tensor</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/layers/conv.jl#L5-L19">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.masked_mse-Tuple{Any, Any, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.masked_mse-Tuple{Any, Any, Any}"><code>VeryBasicCNN2.masked_mse</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">masked_mse(predictions, targets, mask)</code></pre><p>Compute MSE only on masked (valid) entries.</p><p><strong>Arguments</strong></p><ul><li><code>predictions</code>: Model predictions</li><li><code>targets</code>: Ground truth values</li><li><code>mask</code>: Boolean mask indicating valid entries</li></ul><p><strong>Returns</strong></p><ul><li>Mean squared error over masked entries</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/loss.jl#L54-L66">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.maxpool-Tuple{Any}"><a class="docstring-binding" href="#VeryBasicCNN2.maxpool-Tuple{Any}"><code>VeryBasicCNN2.maxpool</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">maxpool(x; pool_size=(2,1), stride=(1,1))</code></pre><p>Apply 2D max pooling to 4D tensor (height, width, channels, batch).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L65-L69">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.model2cpu-Tuple{SeqCNN}"><a class="docstring-binding" href="#VeryBasicCNN2.model2cpu-Tuple{SeqCNN}"><code>VeryBasicCNN2.model2cpu</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">model2cpu(model::SeqCNN)</code></pre><p>Convert SeqCNN model from GPU to CPU.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: SeqCNN instance (potentially on GPU)</li></ul><p><strong>Returns</strong></p><ul><li>SeqCNN instance with all arrays moved to CPU</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">model_cpu = model2cpu(model)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/convert.jl#L5-L20">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.model2gpu-Tuple{SeqCNN}"><a class="docstring-binding" href="#VeryBasicCNN2.model2gpu-Tuple{SeqCNN}"><code>VeryBasicCNN2.model2gpu</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">model2gpu(model::SeqCNN)</code></pre><p>Convert SeqCNN model from CPU to GPU.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: SeqCNN instance (potentially on CPU)</li></ul><p><strong>Returns</strong></p><ul><li>SeqCNN instance with all arrays moved to GPU</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">model_gpu = model2gpu(model)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/convert.jl#L51-L66">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.normalize_filters_l2-Tuple{Any}"><a class="docstring-binding" href="#VeryBasicCNN2.normalize_filters_l2-Tuple{Any}"><code>VeryBasicCNN2.normalize_filters_l2</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">normalize_filters_l2(filters; softmax_alpha=SOFTMAX_ALPHA, use_sparsity=false)</code></pre><p>L2-normalize convolutional filters with optional sparsity-inducing weighting.</p><p><strong>Arguments</strong></p><ul><li><code>filters</code>: 4D filter tensor</li><li><code>softmax_alpha</code>: Strength of sparsity (higher = more sparse)</li><li><code>use_sparsity</code>: Whether to apply softmax sparsity weighting</li></ul><p><strong>Returns</strong></p><ul><li>L2-normalized filters</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L162-L174">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.normalize_squared-Tuple{Any}"><a class="docstring-binding" href="#VeryBasicCNN2.normalize_squared-Tuple{Any}"><code>VeryBasicCNN2.normalize_squared</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">normalize_squared(matrix; ϵ=1e-5, reverse_comp=false)</code></pre><p>Normalize matrix by squaring elements and normalizing columns. Optionally concatenates reverse complement.</p><p><strong>Process</strong></p><ol><li>Square all elements and add ϵ</li><li>Normalize by column sums (creates probability distribution)</li><li>Optionally create reverse complement and concatenate</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L116-L126">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.nucleotide_ranges-Tuple{}"><a class="docstring-binding" href="#VeryBasicCNN2.nucleotide_ranges-Tuple{}"><code>VeryBasicCNN2.nucleotide_ranges</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">nucleotide_ranges(; kwargs...)</code></pre><p>Hyperparameter ranges optimized for nucleotide sequences (DNA/RNA). 4-letter alphabet, typical motif lengths 6-12nt.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/param_ranges.jl#L37-L42">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.pool_code-Tuple{Any, Any, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.pool_code-Tuple{Any, Any, Any}"><code>VeryBasicCNN2.pool_code</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">pool_code(code, pool_size, stride; is_base_layer=false, skip_pooling=false)</code></pre><p>Apply pooling to CNN code tensor with proper dimension handling.</p><p><strong>Arguments</strong></p><ul><li><code>code</code>: Input tensor (3D or 4D)</li><li><code>pool_size</code>: Size as (height, width) tuple</li><li><code>stride</code>: Stride as (height, width) tuple  </li><li><code>is_base_layer</code>: Whether this is the base PWM layer (different indexing)</li><li><code>skip_pooling</code>: If true, only reshape without pooling (identity operation)</li></ul><p><strong>Returns</strong></p><ul><li>Pooled 4D tensor (height, width, channels, batch)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L74-L88">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.pool_output_length-Tuple{Any, Any, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.pool_output_length-Tuple{Any, Any, Any}"><code>VeryBasicCNN2.pool_output_length</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">pool_output_length(input_len, pool_size, stride)</code></pre><p>Output length after pooling: <code>(input_len - pool_size) ÷ stride + 1</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L12-L16">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.predict_from_code-Tuple{SeqCNN, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.predict_from_code-Tuple{SeqCNN, Any}"><code>VeryBasicCNN2.predict_from_code</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">predict_from_code(model::SeqCNN, code; 
                 layer=0,
                 use_sparsity=false,
                 predict_position=nothing,
                 apply_nonlinearity=true)</code></pre><p>Make predictions starting from code at any layer.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: SeqCNN instance</li><li><code>code</code>: Code representation at specified layer</li><li><code>layer</code>: Which layer this code comes from (0 = PWM, 1+ = conv)</li><li><code>use_sparsity</code>: Apply sparsity to remaining layers</li><li><code>predict_position</code>: Predict specific output</li><li><code>apply_nonlinearity</code>: Apply final activation</li></ul><p><strong>Returns</strong></p><ul><li>Predictions</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs"># Get code and predict from it
code = compute_code_at_layer(model, seqs, 2)
preds = predict_from_code(model, code; layer=2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/forward.jl#L209-L235">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.predict_from_sequences-Tuple{SeqCNN, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.predict_from_sequences-Tuple{SeqCNN, Any}"><code>VeryBasicCNN2.predict_from_sequences</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">predict_from_sequences(model::SeqCNN, sequences; 
                      use_sparsity=false, 
                      predict_position=nothing,
                      apply_nonlinearity=true)</code></pre><p>Complete forward pass from sequences to predictions.</p><p><strong>Process</strong></p><ol><li>Extract CNN features</li><li>Linear transformation (output layer)</li><li>Optional nonlinearity (identity by default)</li></ol><p><strong>Arguments</strong></p><ul><li><code>model</code>: SeqCNN instance</li><li><code>sequences</code>: Input sequences</li><li><code>use_sparsity</code>: Apply sparsity-inducing normalization</li><li><code>predict_position</code>: Predict specific output only</li><li><code>apply_nonlinearity</code>: Apply final activation (currently identity)</li></ul><p><strong>Returns</strong></p><ul><li>Predictions (output<em>dim, batch</em>size) or (batch_size,) for single output</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/forward.jl#L166-L188">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.prepare_conv_params-Tuple{LearnedCodeImgFilters, HyperParameters}"><a class="docstring-binding" href="#VeryBasicCNN2.prepare_conv_params-Tuple{LearnedCodeImgFilters, HyperParameters}"><code>VeryBasicCNN2.prepare_conv_params</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">prepare_conv_params(conv_filters::LearnedCodeImgFilters, hp::HyperParameters; use_sparsity=false)</code></pre><p>Prepare convolutional filter parameters.</p><p><strong>Returns</strong></p><ul><li>L2-normalized filters, optionally with sparsity weighting</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/layers/conv.jl#L90-L97">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.prepare_pwm_params-Tuple{LearnedPWMs}"><a class="docstring-binding" href="#VeryBasicCNN2.prepare_pwm_params-Tuple{LearnedPWMs}"><code>VeryBasicCNN2.prepare_pwm_params</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">prepare_pwm_params(pwms::LearnedPWMs; reverse_comp=false)</code></pre><p>Prepare PWM parameters for forward pass.</p><p><strong>Returns</strong></p><ul><li><code>pwm_matrix</code>: Position weight matrix (log odds ratios)</li><li><code>eta</code>: Squared and clamped activation scaler</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/layers/pwm.jl#L47-L55">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.process_code_with_gradient-Tuple{CodeProcessor, Any, Any}"><a class="docstring-binding" href="#VeryBasicCNN2.process_code_with_gradient-Tuple{CodeProcessor, Any, Any}"><code>VeryBasicCNN2.process_code_with_gradient</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">process_code_with_gradient(processor::CodeProcessor, code, gradient; training::Bool=true, step::Union{Nothing, Int}=nothing)</code></pre><p>Process code and gradient features through the processor network.</p><p><strong>Arguments</strong></p><ul><li><code>processor</code>: CodeProcessor instance</li><li><code>code</code>: Code features at inference layer (l, C, 1, n)</li><li><code>gradient</code>: Gradient features at same layer (l, C, 1, n)</li><li><code>training</code>: Whether in training mode</li><li><code>step</code>: Current training step (for temperature annealing). Counts total batches processed.</li></ul><p><strong>Returns</strong></p><ul><li>Processed features (l, C, 1, n) - same size as code</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># In training loop
for (step, batch) in enumerate(dataloader)
    # Temperature decays: 0.5 → 0.1 over ~3000 steps
    output = process_code_with_gradient(proc, code, grad; training=true, step=step)
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/code_processor.jl#L495-L518">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.receptive_field-Tuple{HyperParameters}"><a class="docstring-binding" href="#VeryBasicCNN2.receptive_field-Tuple{HyperParameters}"><code>VeryBasicCNN2.receptive_field</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">receptive_field(hp::HyperParameters)</code></pre><p>Calculate receptive field size in the input sequence at the inference code layer. This accounts for all convolutions, pooling, and strides up to that layer.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/utilities.jl#L5-L10">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.select_output_weights-Tuple{SeqCNN}"><a class="docstring-binding" href="#VeryBasicCNN2.select_output_weights-Tuple{SeqCNN}"><code>VeryBasicCNN2.select_output_weights</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">select_output_weights(model::SeqCNN; predict_position=nothing)</code></pre><p>Select output weights for prediction.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: SeqCNN instance</li><li><code>predict_position</code>: Specific output index (nothing = all outputs)</li></ul><p><strong>Returns</strong></p><ul><li>Output weight matrix or view</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/forward.jl#L129-L140">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.square_clamp-Tuple{Any}"><a class="docstring-binding" href="#VeryBasicCNN2.square_clamp-Tuple{Any}"><code>VeryBasicCNN2.square_clamp</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">square_clamp(x)</code></pre><p>Square and clamp to [0, 0.5] range.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/utils.jl#L200-L204">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.with_batch_size-Tuple{HyperParameters, Int64}"><a class="docstring-binding" href="#VeryBasicCNN2.with_batch_size-Tuple{HyperParameters, Int64}"><code>VeryBasicCNN2.with_batch_size</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">with_batch_size(hp::HyperParameters, new_batch_size::Int)</code></pre><p>Create new HyperParameters with different batch size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/utilities.jl#L36-L40">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.with_efficientnet_mbconv"><a class="docstring-binding" href="#VeryBasicCNN2.with_efficientnet_mbconv"><code>VeryBasicCNN2.with_efficientnet_mbconv</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">with_efficientnet_mbconv(hp::HyperParameters, phi::Int=0)</code></pre><p>Add EfficientNet-style MBConv blocks with compound scaling coefficient φ.</p><p>This uses the standard EfficientNet scaling strategy where φ controls the depth (number of blocks) and width (expansion ratio) of MBConv layers.</p><p><strong>Arguments</strong></p><ul><li><code>hp</code>: Base hyperparameters</li><li><code>phi</code>: EfficientNet scaling coefficient (0-7 for B0-B7)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">hp = generate_random_hyperparameters()
hp_b0 = with_efficientnet_mbconv(hp, 0)  # EfficientNet-B0 style
hp_b2 = with_efficientnet_mbconv(hp, 2)  # EfficientNet-B2 style
hp_b4 = with_efficientnet_mbconv(hp, 4)  # EfficientNet-B4 style</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/utilities.jl#L171-L190">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.with_layernorm"><a class="docstring-binding" href="#VeryBasicCNN2.with_layernorm"><code>VeryBasicCNN2.with_layernorm</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">with_layernorm(hp::HyperParameters, enabled::Bool=true)</code></pre><p>Create new HyperParameters with LayerNorm enabled or disabled.</p><p>LayerNorm is applied after pooling for layers &gt; inference<em>code</em>layer when enabled.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">hp = generate_random_hyperparameters()
hp_ln = with_layernorm(hp, true)   # Enable LayerNorm
hp_no_ln = with_layernorm(hp, false)  # Disable LayerNorm</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/utilities.jl#L62-L75">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VeryBasicCNN2.with_mbconv-Tuple{HyperParameters}"><a class="docstring-binding" href="#VeryBasicCNN2.with_mbconv-Tuple{HyperParameters}"><code>VeryBasicCNN2.with_mbconv</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">with_mbconv(hp::HyperParameters; num_blocks=2, expansion=4)</code></pre><p>Create new HyperParameters with MBConv blocks enabled.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">hp = generate_random_hyperparameters()
hp_mbconv = with_mbconv(hp; num_blocks=3, expansion=6)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/VeryBasicCNN2.jl/blob/fbabdf49a0effe3b4cee7a84b79e8176e5951afc/src/hyperparameters/utilities.jl#L97-L107">source</a></section></details></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 27 November 2025 00:35">Thursday 27 November 2025</span>. Using Julia version 1.12.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
